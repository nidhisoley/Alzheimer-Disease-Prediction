{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb255d1",
   "metadata": {},
   "source": [
    "### Importing necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10328d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, StratifiedKFold,KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced34c48",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d7b9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>MRI ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Visit</th>\n",
       "      <th>MR Delay</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR1</td>\n",
       "      <td>Demented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1678</td>\n",
       "      <td>0.736</td>\n",
       "      <td>1.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR2</td>\n",
       "      <td>Demented</td>\n",
       "      <td>2</td>\n",
       "      <td>560</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR3</td>\n",
       "      <td>Demented</td>\n",
       "      <td>3</td>\n",
       "      <td>1895</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
       "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
       "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
       "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
       "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
       "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
       "\n",
       "   SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
       "0  2.0  27.0  0.0  1987  0.696  0.883  \n",
       "1  2.0  30.0  0.0  2004  0.681  0.876  \n",
       "2  NaN  23.0  0.5  1678  0.736  1.046  \n",
       "3  NaN  28.0  0.5  1738  0.713  1.010  \n",
       "4  NaN  22.0  0.5  1698  0.701  1.034  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('oasis_longitudinal.csv')\n",
    "\n",
    "# Inspect data\n",
    "# ... YOUR CODE FOR TASK 1 ..\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc206d4",
   "metadata": {},
   "source": [
    "### Summary statistics of the dataset. \n",
    "Summary: This set consists of a longitudinal collection of 150 subjects aged 60 to 96. Each subject was scanned on two or more visits, separated by at least one year for a total of 373 imaging sessions. For each subject, 3 or 4 individual T1-weighted MRI scans obtained in single scan sessions are included. The subjects are all right-handed and include both men and women. 72 of the subjects were characterized as nondemented throughout the study. 64 of the included subjects were characterized as demented at the time of their initial visits and remained so for subsequent scans, including 51 individuals with mild to moderate Alzheimerâ€™s disease. Another 14 subjects were characterized as nondemented at the time of their initial visit and were subsequently characterized as demented at a later visit.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6ab4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Visit     MR Delay         Age        EDUC         SES  \\\n",
      "count  373.000000   373.000000  373.000000  373.000000  354.000000   \n",
      "mean     1.882038   595.104558   77.013405   14.597855    2.460452   \n",
      "std      0.922843   635.485118    7.640957    2.876339    1.134005   \n",
      "min      1.000000     0.000000   60.000000    6.000000    1.000000   \n",
      "25%      1.000000     0.000000   71.000000   12.000000    2.000000   \n",
      "50%      2.000000   552.000000   77.000000   15.000000    2.000000   \n",
      "75%      2.000000   873.000000   82.000000   16.000000    3.000000   \n",
      "max      5.000000  2639.000000   98.000000   23.000000    5.000000   \n",
      "\n",
      "             MMSE         CDR         eTIV        nWBV         ASF  \n",
      "count  371.000000  373.000000   373.000000  373.000000  373.000000  \n",
      "mean    27.342318    0.290885  1488.128686    0.729568    1.195461  \n",
      "std      3.683244    0.374557   176.139286    0.037135    0.138092  \n",
      "min      4.000000    0.000000  1106.000000    0.644000    0.876000  \n",
      "25%     27.000000    0.000000  1357.000000    0.700000    1.099000  \n",
      "50%     29.000000    0.000000  1470.000000    0.729000    1.194000  \n",
      "75%     30.000000    0.500000  1597.000000    0.756000    1.293000  \n",
      "max     30.000000    2.000000  2004.000000    0.837000    1.587000  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 373 entries, 0 to 372\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Subject ID  373 non-null    object \n",
      " 1   MRI ID      373 non-null    object \n",
      " 2   Group       373 non-null    object \n",
      " 3   Visit       373 non-null    int64  \n",
      " 4   MR Delay    373 non-null    int64  \n",
      " 5   M/F         373 non-null    object \n",
      " 6   Hand        373 non-null    object \n",
      " 7   Age         373 non-null    int64  \n",
      " 8   EDUC        373 non-null    int64  \n",
      " 9   SES         354 non-null    float64\n",
      " 10  MMSE        371 non-null    float64\n",
      " 11  CDR         373 non-null    float64\n",
      " 12  eTIV        373 non-null    int64  \n",
      " 13  nWBV        373 non-null    float64\n",
      " 14  ASF         373 non-null    float64\n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 43.8+ KB\n",
      "None\n",
      "\n",
      "\n",
      "    Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  \\\n",
      "356  OAS2_0181  OAS2_0181_MR1     Demented      1         0   F    R   74   \n",
      "357  OAS2_0181  OAS2_0181_MR2     Demented      2       539   F    R   75   \n",
      "358  OAS2_0181  OAS2_0181_MR3     Demented      3      1107   F    R   77   \n",
      "359  OAS2_0182  OAS2_0182_MR1     Demented      1         0   M    R   73   \n",
      "360  OAS2_0182  OAS2_0182_MR2     Demented      2       776   M    R   75   \n",
      "361  OAS2_0183  OAS2_0183_MR1  Nondemented      1         0   F    R   66   \n",
      "362  OAS2_0183  OAS2_0183_MR2  Nondemented      2       182   F    R   66   \n",
      "363  OAS2_0183  OAS2_0183_MR3  Nondemented      3       732   F    R   68   \n",
      "364  OAS2_0183  OAS2_0183_MR4  Nondemented      4      2107   F    R   72   \n",
      "365  OAS2_0184  OAS2_0184_MR1     Demented      1         0   F    R   72   \n",
      "366  OAS2_0184  OAS2_0184_MR2     Demented      2       553   F    R   73   \n",
      "367  OAS2_0185  OAS2_0185_MR1     Demented      1         0   M    R   80   \n",
      "368  OAS2_0185  OAS2_0185_MR2     Demented      2       842   M    R   82   \n",
      "369  OAS2_0185  OAS2_0185_MR3     Demented      3      2297   M    R   86   \n",
      "370  OAS2_0186  OAS2_0186_MR1  Nondemented      1         0   F    R   61   \n",
      "371  OAS2_0186  OAS2_0186_MR2  Nondemented      2       763   F    R   63   \n",
      "372  OAS2_0186  OAS2_0186_MR3  Nondemented      3      1608   F    R   65   \n",
      "\n",
      "     EDUC  SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
      "356    12  NaN  26.0  0.5  1171  0.733  1.499  \n",
      "357    12  NaN   NaN  1.0  1169  0.742  1.501  \n",
      "358    12  NaN   NaN  1.0  1159  0.733  1.515  \n",
      "359    12  NaN  23.0  0.5  1661  0.698  1.056  \n",
      "360    12  NaN  20.0  0.5  1654  0.696  1.061  \n",
      "361    13  2.0  30.0  0.0  1495  0.746  1.174  \n",
      "362    13  2.0  30.0  0.0  1506  0.740  1.165  \n",
      "363    13  2.0  30.0  0.0  1506  0.740  1.165  \n",
      "364    13  2.0  30.0  0.0  1510  0.723  1.162  \n",
      "365    16  3.0  24.0  0.5  1354  0.733  1.296  \n",
      "366    16  3.0  21.0  1.0  1351  0.708  1.299  \n",
      "367    16  1.0  28.0  0.5  1704  0.711  1.030  \n",
      "368    16  1.0  28.0  0.5  1693  0.694  1.037  \n",
      "369    16  1.0  26.0  0.5  1688  0.675  1.040  \n",
      "370    13  2.0  30.0  0.0  1319  0.801  1.331  \n",
      "371    13  2.0  30.0  0.0  1327  0.796  1.323  \n",
      "372    13  2.0  30.0  0.0  1333  0.801  1.317  \n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics\n",
    "df_desc= df.describe()\n",
    "print(df_desc)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print DataFrame information\n",
    "df_info = df.info()\n",
    "print(df_info)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(df.tail(17))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ff39f",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null value with their column mean and median\n",
    "df[\"SES\"].fillna(df[\"SES\"].median(), inplace=True)\n",
    "df[\"MMSE\"].fillna(df[\"MMSE\"].mean(), inplace=True)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d77b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how many people have Alzheimer\n",
    "#same person visits two or more time so only take the single visit data\n",
    "sns.set_style(\"whitegrid\")\n",
    "ex_df = df.loc[df['Visit'] == 1]\n",
    "sns.countplot(x='Group', data=ex_df)\n",
    "\n",
    "\n",
    "#We have three groups so convert Converted Group Into Demented\n",
    "\n",
    "ex_df['Group'] = ex_df['Group'].replace(['Converted'], ['Demented'])\n",
    "df['Group'] = df['Group'].replace(['Converted'], ['Demented'])\n",
    "sns.countplot(x='Group', data=ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd9f964",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demented = ex_df[ex_df['Group']=='Demented']['M/F'].value_counts()\n",
    "Nondemented = ex_df[ex_df['Group']=='Nondemented']['M/F'].value_counts()\n",
    "df_bar = pd.DataFrame([Demented,Nondemented])\n",
    "df_bar.index = ['Demented','Nondemented']\n",
    "df_bar.plot(kind='bar',stacked=True, figsize=(8,5))\n",
    "print(df_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56453505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots which shows the IQR(Interquartile Range )\n",
    "fig, axes = plt.subplots(2,3,figsize = (16,7))\n",
    "fig.suptitle(\"Box Plot\",fontsize=14)\n",
    "sns.set_style(\"whitegrid\")\n",
    "l=['SES','EDUC','MMSE','CDR','ETIV','ASF']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_title(l[i])\n",
    "\n",
    "\n",
    "sns.boxplot(data=df['SES'], orient=\"v\",width=0.4, palette=\"colorblind\",ax = axes[0][0]);\n",
    "sns.boxplot(data=df['EDUC'], orient=\"v\",width=0.4, palette=\"colorblind\",ax = axes[0][1]);\n",
    "sns.boxplot(data=df['MMSE'], orient=\"v\",width=0.4, palette=\"colorblind\",ax = axes[0][2]);\n",
    "sns.boxplot(data=df['CDR'], orient=\"v\",width=0.4, palette=\"colorblind\",ax = axes[1][0]);\n",
    "sns.boxplot(data=df['eTIV'], orient=\"v\",width=0.4, palette=\"colorblind\",ax = axes[1][1]);\n",
    "sns.boxplot(data=df['ASF'], orient=\"v\",width=0.4, palette=\"colorblind\",ax = axes[1][2]);\n",
    "#xlabel(\"Time\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_map( df ):\n",
    "    corr = df.corr()\n",
    "    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
    "    cmap = sns.diverging_palette( 240 , 10 , as_cmap = True )\n",
    "    _ = sns.heatmap(corr,cmap = cmap,square=True, cbar_kws={ 'shrink' : .9 }, ax=ax, annot = True, annot_kws = { 'fontsize' : 12 })\n",
    "plot_correlation_map(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934c2e1",
   "metadata": {},
   "source": [
    "### Selecting important features that are most crucial in detecting early Alzheimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "l=['Group','M/F','Hand']\n",
    "# Encode labels in column 'species'.\n",
    "for i in l:\n",
    "    ex_df[i]= label_encoder.fit(ex_df[i])\n",
    "  \n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ex_df.iloc[:,5:15]\n",
    "y = ex_df.iloc[:,2]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d18925",
   "metadata": {},
   "source": [
    "### 1. K-best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(score_func=chi2, k=8)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083fb78e",
   "metadata": {},
   "source": [
    "### 2. Extra Tress Classifies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66416d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(8).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd843e",
   "metadata": {},
   "source": [
    "### 3. Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1,50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv=GridSearchCV(knn,param_grid,cv=5)\n",
    "sfs = SequentialFeatureSelector(knn_cv,n_features_to_select=8)\n",
    "sfs.fit(X, y)\n",
    "\n",
    "print(sfs.get_support(indices=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38eee82",
   "metadata": {},
   "source": [
    "### From all the three methods we observe that the following features are of the highest importance-\n",
    "1. CDR\tClinical Dementia Rating\n",
    "2. MMSE\tMini Mental State Examination\n",
    "3. EDUC\tYears of Education\n",
    "4. eTIV\tEstimated Total Intracranial Volume\n",
    "5. SES\tSocioeconomic Status\n",
    "6. nWBV\tNormalize Whole Brain Volume\n",
    "7. ASF\tAtlas Scaling Factor\n",
    "8. M/F Male/Female\n",
    "\n",
    "No garbage in No garbage out. So, we will implement the models using these 7 features only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b16c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_names = [\"M/F\", \"EDUC\", \"SES\", \"MMSE\", \"eTIV\", \"nWBV\", \"ASF\", 'CDR']\n",
    "predicted_class_names = ['Group']\n",
    "\n",
    "Xf = ex_df[feature_col_names].values\n",
    "yf = ex_df[predicted_class_names].values\n",
    "\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(Xf, yf, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "models.append(( 'LR' , LogisticRegression()))\n",
    "models.append(( 'LDA' , LinearDiscriminantAnalysis()))\n",
    "models.append(( 'KNN' , KNeighborsClassifier()))\n",
    "models.append(( 'DT' , BaggingClassifier()))\n",
    "models.append(( 'NB' , GaussianNB()))\n",
    "models.append(( 'SVM' , SVC()))\n",
    "models.append(( 'RF' , RandomForestClassifier()))\n",
    "models.append(( 'NN' , MLPClassifier( activation='tanh', solver='lbfgs', max_iter=50000)))\n",
    "\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7 \n",
    "scoring =  'accuracy'\n",
    "\n",
    "# Test options and evaluation metric\n",
    "num_instances = len(X_train)\n",
    "seed = 7 \n",
    "scoring =  'accuracy'\n",
    "results = []\n",
    "names = []\n",
    "kfold = KFold()\n",
    "display(\"Model:  Accuracy  Std\")\n",
    "for name, model in models:\n",
    " cv_results = cross_val_score(model, Xf_train, yf_train, cv=kfold, scoring=scoring)\n",
    " results.append(cv_results)\n",
    " names.append(name)\n",
    " msg = \"%s:\\t%.2f%s\\t(%f)\" % (name, cv_results.mean()*100,\"%\", cv_results.std())\n",
    " print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f7762",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle( 'Algorithm Comparison' )\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373169dc",
   "metadata": {},
   "source": [
    "### Scaling the feature to see if the their is change in the accuracy of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(( 'ScaledLR' , Pipeline([( 'Scaler' , StandardScaler()),( 'LR' ,\n",
    "    LogisticRegression())])))\n",
    "pipelines.append(( 'ScaledLDA' , Pipeline([( 'Scaler' , StandardScaler()),( 'LDA' ,\n",
    "    LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(( 'ScaledKNN' , Pipeline([( 'Scaler' , StandardScaler()),( 'KNN' ,\n",
    "    KNeighborsClassifier())])))\n",
    "\n",
    "pipelines.append(( 'ScaledNB' , Pipeline([( 'Scaler' , StandardScaler()),( 'NB' ,\n",
    "    GaussianNB())])))\n",
    "pipelines.append(( 'ScaledSVM' , Pipeline([( 'Scaler' , StandardScaler()),( 'SVM' , SVC())])))\n",
    "pipelines.append(( 'ScaledNN' , Pipeline([( 'Scaler' , StandardScaler()),( 'NN' ,MLPClassifier( activation='tanh', solver='lbfgs', max_iter=50000))])))\n",
    "\n",
    "pipelines.append(( 'ScaledDT' , Pipeline([( 'Scaler' , StandardScaler()),( 'DT' , BaggingClassifier())])))\n",
    "pipelines.append(( 'ScaledRF' , Pipeline([( 'Scaler' , StandardScaler()),( 'RF' ,  RandomForestClassifier())])))\n",
    "results = []\n",
    "names = []\n",
    "display(\"Model    Accuracy    Std\")\n",
    "for name, model in pipelines:\n",
    "  kfold = KFold()\n",
    "  cv_results = cross_val_score(model, Xf_train, yf_train, cv=kfold,\n",
    "      scoring=scoring)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  \n",
    "  msg = \"%s:\\t%.2f%s\\t(%f)\" % (name, cv_results.mean()*100,\"%\", cv_results.std())\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245747ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle( 'Algorithm Comparison' )\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names, rotation ='90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d433b7c",
   "metadata": {},
   "source": [
    "### Models that perform good after scaling:\n",
    "### LR, LDA, NB, SVM, RF\n",
    "##### Lets tune the hyperparameters for these individually. The NB, LR, LDA, SVM have the same level of accuracy, so we only try to tune the parameters of SVM and LR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2500fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. SVM\n",
    "#Make Support Vector Classifier Pipeline\n",
    "pipe_svc = Pipeline([( 'scl' , StandardScaler()),( 'clf' , SVC())])\n",
    "\n",
    "#Fit Pipeline to training Data\n",
    "pipe_svc.fit(Xf_train, yf_train)\n",
    "\n",
    "#print('--> Fitted Pipeline to training Data')\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_svc, X=Xf_train, y=yf_train)\n",
    "print('--> Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "#Tune Hyperparameters\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'clf__C': param_range,'clf__kernel': ['linear']},\n",
    "              {'clf__C': param_range,'clf__gamma': param_range,\n",
    "               'clf__kernel': ['rbf']}]\n",
    "gs_svc = GridSearchCV(estimator=pipe_svc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  n_jobs=1)\n",
    "gs_svc = gs_svc.fit(Xf_train, yf_train)\n",
    "yf_pred = gs_svc.predict(Xf_test)\n",
    "\n",
    "print(confusion_matrix(yf_test, yf_pred))\n",
    "print('--> Tuned Parameters Best Score: ',gs_svc.best_score_)\n",
    "print('--> Best Parameters: \\n',gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66efc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. LR\n",
    "# Setup the hyperparameter grid\n",
    "\n",
    "pipe_lr = Pipeline([( 'Scaler' , StandardScaler()),( 'LR' ,\n",
    "    LogisticRegression())])\n",
    "            \n",
    "#Fit Pipeline to training Data\n",
    "pipe_lr.fit(Xf_train, yf_train) \n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr, \n",
    "                         X=Xf_train, \n",
    "                         y=yf_train, \n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('--> Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "#Tune Hyperparameters\n",
    "param_grid={'LR__solver'  :['newton-cg', 'lbfgs', 'liblinear'],'LR__penalty':['l2'],'LR__C' : [100, 10, 1.0, 0.1, 0.01]}\n",
    "\n",
    "# instantiate the grid\n",
    "gs_lr = GridSearchCV(pipe_lr, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=10, \n",
    "                    scoring='accuracy')\n",
    "gs_lr = grid.fit(Xf_train, yf_train)\n",
    "yf_pred = grid.predict(Xf_test)\n",
    "print(confusion_matrix(yf_test, yf_pred))\n",
    "print('--> Tuned Parameters Best Score: ',grid.best_score_)\n",
    "print('--> Best Parameters: \\n',grid.best_params_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Support Vector Classifier Pipeline\n",
    "pipe_rf = Pipeline([( 'scl' , StandardScaler()),( 'clf' , RandomForestClassifier())])\n",
    "\n",
    "#Fit Pipeline to training Data\n",
    "pipe_rf.fit(Xf_train, yf_train)\n",
    "\n",
    "#print('--> Fitted Pipeline to training Data')\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_rf, X=Xf_train, y=yf_train)\n",
    "print('--> Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "#Tune Hyperparameters\n",
    "\n",
    "param_grid = [{'clf__n_estimators' : [10, 100, 1000],\n",
    "'clf__max_features' : ['sqrt', 'log2']}]\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  n_jobs=1)\n",
    "gs_rf = gs_rf.fit(Xf_train, yf_train)\n",
    "yf_pred = gs_rf.predict(Xf_test)\n",
    "\n",
    "print(confusion_matrix(yf_test, yf_pred))\n",
    "print('--> Tuned Parameters Best Score: ',gs_rf.best_score_)\n",
    "print('--> Best Parameters: \\n',gs_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acac0be",
   "metadata": {},
   "source": [
    "### Apply the hyperparametered model on the test set and select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efeb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function of accuracy\n",
    "total_accuracy = {}\n",
    "def accuracy(model):\n",
    "    pred = model.predict(Xf_test)\n",
    "    accu = metrics.accuracy_score(yf_test,pred)\n",
    "    print(\"\\nAcuuracy Of the Model: \",accu,\"\\n\\n\")\n",
    "    total_accuracy[str((str(model)))] = accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for ploting confusion metrix\n",
    "def plot_confusion_metrix(y_test,model_test):\n",
    "    cm = metrics.confusion_matrix(y_test, model_test)\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.summer)\n",
    "    classNames = ['Nondemented','Demented']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edae56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. SVM with best parameter on test set\n",
    "clf_svc = gs_svc.best_estimator_\n",
    "\n",
    "#Get Final Scores\n",
    "clf_svc.fit(Xf_train, yf_train)\n",
    "scores = cross_val_score(estimator=clf_svc,\n",
    "                         X=Xf_train,\n",
    "                         y=yf_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "\n",
    "print('--> Final Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "print('--> Final Accuracy on Test set: %.5f' % clf_svc.score(Xf_test,yf_test))\n",
    "accuracy(clf_svc)\n",
    "plot_confusion_metrix(yf_test,clf_svc.predict(Xf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffddf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. LR: Using best parameters on test set\n",
    "\n",
    "clf_lr = grid.best_estimator_\n",
    "#Get Final Scores\n",
    "clf_lr.fit(Xf_train, yf_train)\n",
    "scores = cross_val_score(estimator=clf_lr,\n",
    "                         X=Xf_train,\n",
    "                         y=yf_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "\n",
    "\n",
    "print('--> Final Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "print('--> Final Accuracy on Test set: %.5f' % clf_lr.score(Xf_test,yf_test))\n",
    "accuracy(clf_lr)\n",
    "plot_confusion_metrix(yf_test,clf_lr.predict(Xf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. RF: using the best parameters on the test set\n",
    "clf_rf = gs_rf.best_estimator_\n",
    "\n",
    "#Get Final Scores\n",
    "clf_rf.fit(Xf_train, yf_train)\n",
    "scores = cross_val_score(estimator=clf_rf,\n",
    "                         X=Xf_train,\n",
    "                         y=yf_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "\n",
    "print('--> Final Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "print('--> Final Accuracy on Test set: %.5f' % clf_rf.score(Xf_test,yf_test))\n",
    "accuracy(clf_rf)\n",
    "plot_confusion_metrix(yf_test,clf_rf.predict(Xf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4e998",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48306852",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = total_accuracy.values()\n",
    "labels = ['SVC','LR','RF']\n",
    "plt.plot([i for i, e in enumerate(data)], data, 'ro'); plt.xticks([i for i, e in enumerate(labels)], [l[0:16] for l in labels])\n",
    "plt.title(\"Model Vs Accuracy\",fontsize = 14)\n",
    "plt.xlabel('Model',fontsize = 13)\n",
    "plt.xticks(rotation = 50)\n",
    "plt.ylabel('Accuracy',fontsize = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c526c7",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "1. We found that SVC and LR both would be best models for predicting the Alzheimers.\n",
    "2. The CDR (Clinical Dementia Rating) and MMSE\t(Mini Mental State Examination) are very good parameters for detecting dementia at an early stage. So the clinician can improve improve these testing and the questionnaire. This would also help in improving the model accuracy.\n",
    "3. The SVC and LR models give an accuracy of 88% on the testing set with zero false negative values, which is a remarkable as it would not detect any patient with Demnetia as non Demented. \n",
    "4. The cons of the model is that the data set is small and only for the patients of the same age group. We could improve our model by adding more features with varied range of ages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b820200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
